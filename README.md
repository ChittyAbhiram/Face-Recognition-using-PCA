# Face-Recognition-using-PCA
The Principal Component Analysis ( is one of the most effective image recognition and compression algorithms ever developed [ PCA reduces the huge dimensionality of the data space (observed variables) to the smaller intrinsic dimensionality of feature space (independent variables), which is required to economically characterize the data. 

The covariance matrix of a training image set yields these eigenvectors [2],[ The weights are calculated after determining a set of the most relevant eigenfaces. A support vector classifier obtains project input images to principal components and classification. The amount of variance retained is misgiven by the number of principal components we choose. The dataset is obtained from the Github repository Code Heroku and implemented using python3.

# CONCLUSION:
From this study we can determine that a lower dimensional space exists that can more efficiently represent a dataset(closely). PCA finds such low-dimensional projections that maximally preserve variance in the data. The amount of variance retained is given by several principal components we choose. Here, 4096 features were reduced to 150 and the model built gives weighted average precision of of 0.98 and a recall of 0.93. We get 93% accuracy of face recognition.

# REFERENCE:
[1]
Erwin et al 2019 J. Phys.: Conf. Ser. 1196 012010
https://iopscience.iop.org/article/10.1088/1742 6596/1196/1/012010/pdf
[2]
Liton Chandra Paul Abdulla Al Sumam, Face Recognition Using Principal Component
Analysis Method, International Journal of Advanced Research in Computer Engineering
Technology ( Volume 1, Issue 9, November 2012.
http://ijarcet.org/wp content/uploads/IJARCET VOL 1 ISSUE 9 135 139.pdf
[3]
M.A. Turk and A.P. Pentland, “Face Recognition Using Eigenfaces”, IEEE Conf. on
Computer Vision and Pattern Recognition, pp. 586 591, 1991.
7
